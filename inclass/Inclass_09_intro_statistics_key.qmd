---
title: "Inclass_09"
author: "Darrell Sonntag"
date: "2024-02-04"
output: html
---

```{r}
#| include: False

library(tidyverse)
library(knitr)
```

Objectives: 
- load in ozone data
- create simple plots
- Calculate 95% confidence intervals of the mean I/O
- Evaluate assumptions for 95% confidence intervals, and make adjustments if needed to the data
- Conduct a t-tests on the significance of the differences
- Create plots with error bars
- Create bivariate plot with UDAQ data, add in linear model fit
- Include linear correlation plot

- read in the ozone.wide data that we created in HW2. 
- Read in my version, just to make sure there are not differences with how they did it for the homework

```{r}

ozone.wide <- read_csv(
              "..//CE594R_25_data_science_class//data//ozone.I.O.csv") |> 
              rename(ac.type = `Type of Air Conditioner`) 

```


Plot the average indoor/outdoor ratio with a separate panel for the homes with different Type of Air Conditioners
- Use the ozone.wide dataframe from HW_2 ozone
- Let's read in the same data, so that we are all working from the same observation
- On the x-axis have each home  
- Jitter the points so you can see where there multiple visits from one house


names(ozone.wide)
```{r}

ggplot(data = ozone.wide,aes(x = House.Number, y = In_Out_ratio,fill=ac.type)) + 
  geom_jitter(size=2,alpha=0.9,width=0.2,pch=21,color='black')+
  theme_bw()+
   labs(x='House', y= 'I/O')+
  facet_grid(.~ac.type, scales='free') +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks=seq(0,1,.20))+
  theme(legend.position = 'blank')+
  theme(axis.text.y = element_text(size=9),axis.text.x = element_text(angle = 90,vjust =0.5, size=8))
     

```


Sort the House IDs by the size of the mean I/O ratio

```{r}

## Calculate means

ozone.mean <- ozone.wide |> 
              group_by(House.Number) |> 
              summarize(avg.io = mean(In_Out_ratio),count=n()) |> 
              arrange(avg.io)

## Make House.Number be a factor, ordered according to the levels of the average indoor outdoor ratio

ozone.wide <- ozone.wide |> 
              mutate(House.Number =
              factor(House.Number,levels=ozone.mean$House.Number,
                     ordered=T)) 

            
```
Replot

```{r}

ggplot(data = ozone.wide,aes(x = House.Number, y = In_Out_ratio,fill=ac.type)) + 
  geom_jitter(size=2,alpha=0.9,width=0.2,pch=21,color='black')+
  theme_bw()+
   labs(x='House', y= 'I/O')+
  facet_grid(.~ac.type, scales='free') +
  coord_cartesian(ylim = c(0, 1)) +
  scale_y_continuous(breaks=seq(0,1,.20))+
  theme(legend.position = 'blank')+
  theme(axis.text.y = element_text(size=9),axis.text.x = element_text(angle = 90,vjust =0.5, size=8))
     


     

```

```{r}
ggsave(".//inclass//ozone.indoor.outdoor.png", width=6.5, height=4, units="in")
```
 
Calculate the mean of the two distributions and calculate 95% confidence intervals of the mean using the t-distribution 

$$
\bar{x}\,\pm t_{\alpha/2,n-1} \, \cdot \frac{s}{\sqrt{n}}
$$
Use a group_by and summarize
Calculate the t-critical value using
mutate(tcrit = qt(.975,df=(n-1))) %>% ## two-sided 

?qt
Print the table using kable

```{r}
t.intervals <- ozone.wide |> 
               group_by(ac.type) |> 
               summarize(avg.io = mean(In_Out_ratio),
                         sd = sd(In_Out_ratio),
                         n = sum(!is.na(In_Out_ratio))) |> 
              mutate(tcrit = qt(.995,df=(n-1))) |>  ## two-sided 
              mutate(lower.bound = avg.io - tcrit*sd/sqrt(n),
                     upper.bound = avg.io + tcrit*sd/sqrt(n))

```


Plot the means with the confidence intervals
- Use geom_col for the means
- Use geom_errorbar for the confidence intervals

```{r}
plot.conf.int.1 <- ggplot(t.intervals,aes(x=ac.type,y=avg.io,fill=ac.type))+
    geom_col()+
    geom_errorbar(aes(ymin=lower.bound,ymax=upper.bound),width=0.5)+
    coord_cartesian(ylim = c(0,.8))

plot.conf.int.1

```

Are mean I/O ratio between the two types of homes significantly different?

Are there any issues with our assumptions on the error bars?

- t-distribution
Good overview here (or a statistics text book)
  <https://canvas.harvard.edu/files/1170856/download?download_frd=1>
- We assume the our population is approximately normal (although the t-distribution is fairly robust to departures of normality if our n is large)
  - What is our N?
  
  
- How can we evaluate if our observations are approximately normal? 

- We can plot the data-- histogram?


```{r}

hg <- ggplot(ozone.wide,aes(x=In_Out_ratio,fill=ac.type))+
      geom_histogram(bins = 12) +
      geom_density(alpha=0.2)+
      facet_grid(.~ac.type,scales='free')


hg
```

- What other plots? quantile-quantile plot
  
- What is a Normal qqplot?

<https://library.virginia.edu/data/articles/understanding-q-q-plots>

-  You plot the standard normal values (z-scores) on the x-axis for each percentile point (depends on your n)

$$ Z = \frac{x-\mu}{\sigma} $$
Reminder of the standard normal distribution is here: 
<https://online.stat.psu.edu/stat200/book/export/html/124>

Standard normal curves from my statistics text book: 
<https://www.stat.purdue.edu/~chakrabp/TABLES/tablea3.pdf>

You can order the data (calculate the percentiles or cumulative distribution function), and what z-score is associated with that percentile. 

Then you could plot the actual z-score on the y, and the inferred z-score based on its order on the x-axis. 

If the data is normally distributed, the data should be plotted on a line. 





-  You plot the actual value on the y. 
-  If it is from a normal distributions, the values should approximately fall on a line

- For example: 
- Look at 9 randomly generated samples from a normal distribution of 50 observations
- from  Julian J. Faraway. Linear Models with R. Chapman and Hall/CRC, 2014.
- Available at the BYU library


```{r}

# use the base R functions qqnorm and qqline to plot a Normal q-q plot for a set of data
n <- 50
par(mfrow=c(3,3))
for(i in 1:9) {x <- rnorm(n); qqnorm(x); qqline(x)}

```

### "Homemade' qq plot

filter just the 'AC' homes

Arrange my data from smallest to largest In_Out
Add an order sequene
Calculate the percentile of hte order
Calculate the z_score using qnorm(percentile)

plot the z-score on the x-axis, and the In_Out_ration on the y


```{r}
ozone.wide.AC <- ozone.wide %>%
                 filter(ac.type=='Central') %>%
                 arrange(In_Out_ratio) %>%
                 mutate(ord = seq(1:n())) %>%
                 mutate(z_score_1 = (In_Out_ratio-mean(In_Out_ratio))/sd(In_Out_ratio)) |> 
                 mutate(percentile = ord/(n()+1)) %>%
                 mutate(z_score = qnorm(percentile)) ## This calculates the z-score depending on the percentiles, or the inverse of the cumulative distribution function for the standard normal distribution
                 
ggplot(ozone.wide.AC, aes(x=z_score,y=z_score_1)) +
    geom_point()    

```

# Use ggplot functions

<https://ggplot2.tidyverse.org/reference/geom_qq.html>

```{r}

ozone.wide.AC <- ozone.wide %>%
                 filter(`ac.type` == 'Central') %>%
                 arrange(In_Out_ratio) %>%
                 mutate(ord = seq(1:n())) %>%
                 mutate(percentile = ord/(n()+1)) %>%
                 mutate(percentile_2 =  seq(from=1/length(In_Out_ratio),to=1,by=1/length(In_Out_ratio))) %>%
                 mutate(z_score_2 = qnorm(percentile_2)) %>%
                 mutate(z_score = qnorm(percentile)) ## This calculates the z-score depending on the percentiles, or the inverse of the quantile density function



  
  
ggplot(ozone.wide.AC, aes(x=z_score,y=In_Out_ratio)) +
    geom_point()+
    labs(title = 'Normal q-q plot')

```
## Let's use the ggplot functions

<https://ggplot2.tidyverse.org/reference/geom_qq.html>

assign the plot to be qq

```{r}

qq<- ggplot(ozone.wide, aes(sample=In_Out_ratio,color=ac.type))+
  geom_qq()+
  geom_qq_line()+
  facet_grid(.~ac.type)

qq

```
- Do the data appear to be normally distributed?
- Central visits looks better than Evaporative visits.
- Also could be an issue of the small sample size. 

- For now, I'm going to assume that the distribution is approximately normal

- We can have two plots side by side

<https://ggplot2-book.org/arranging-plots>

```{r}

library(patchwork)

hg + qq + plot_layout(ncol = 1)


```

What other assumptions do we have?
  <https://canvas.harvard.edu/files/1170856/download?download_frd=1>

- We assumed that our observations were independent random observations from the same population
- Is that true?

- Our data are not independent observations from the same population. We have several repeat observations from the same homes. These observations appear correlated to one another 
- they are clustered together on the graph
- 

- Let's say  we kept kept re-sampling I/O ratios from the same homes (perhaps each home 100 times). So our N became very large. What would happen to our confidence intervals? Because our observations are 
- Decrease by a factor of 1/sqrt(n). 
- then our confidence intervals. However, we still would be limited to the same number of homes.... W
- Would would have more confidence in the 30 homes we sampled, but would we have a much better estimate of mean I/O ratio for all homes in the population? 
- No-- because we are still sampling the same 30 homes, we haven't expanded our sample


- Also, could there be any relationship of the observations with Date Sampled?
- hmm. it does seem like there is some correlation among observations occurring on the same day, for the Central AC homes...
- However, there doesn't seem like a systematic trend across time. 
- Also, I'm less considered about the Central AC homes because these are 'worst case scenarios' typically the values were below the detection limit
- I'm going to ignore it because it will take more complex methods to address both.
- This could be a real issue. What if there was a strong impact of the date sampled, and it so happened that we measured the Evaporative homes on days with high outdoor ozone, that tended to have higher I/O ratios than the evaporative cooler days?

```{r}
ozone.wide <- ozone.wide %>%
      mutate(year = year(`Date Sampled`))


ggplot(data = ozone.wide,aes(x = `Date Sampled`, y = In_Out_ratio,fill=`House.Number`)) + 
  geom_jitter(size=2,alpha=0.9,width=0.2,pch=21,color='black')+
  theme_bw()+
   labs(x='House', y= 'I/O')+
  facet_grid(ac.type~ year, scales='free') +
  expand_limits(y=0)+ 
  theme(axis.text.y = element_text(size=9),axis.text.x = element_text(angle = 90,vjust =0.5, size=8))
   

```

How can we remove the dependence within our data set with multiple observations from each home?
- Just keep the first measurement from each home. 
  - Throw away all the follow up measurements? 
- Calculate the mean from each home, treat that as our random variable
  - Each mean of the home, can be considered a random sample, with independent and identically distributed (iid) observations


```{r}
mean.ozone <- ozone.wide |> 
              group_by(House.Number,ac.type) |> 
              summarize(avg.io = mean(In_Out_ratio), n=sum(!is.na(In_Out_ratio)))

```

Now calculate the average of the averages, and a 95% confidence intervals

Print the table using kable

```{r}


mean.mean <- mean.ozone |> 
             group_by(ac.type) |> 
             summarize(avg.io.type = mean(avg.io),
                       sd =sd(avg.io),
                       n = sum(!is.na(avg.io))) |> 
                       mutate(tcrit = qt(.975,df=(n-1))) |>  ## two-sided 
                       mutate(lower.bound = avg.io.type - tcrit*sd/sqrt(n),
                      upper.bound = avg.io.type + tcrit*sd/sqrt(n)) 

kable(mean.mean)

```

Plot the means with the confidence intervals
- Use geom_col for the means
- Use geom_errorbar for the confidence intervals

```{r}

plot.conf.int.2 <- ggplot(mean.mean,aes(x=ac.type,y=avg.io.type,fill=ac.type))+
                  geom_col()+
                  geom_errorbar(aes(ymin=lower.bound,ymax=upper.bound),width=0.5) +
                  coord_cartesian(ylim = c(0,.8))

plot.conf.int.2


```
```{r}

plot.conf.int.1 + plot.conf.int.2 + plot_layout(ncol = 2)

```






Calculate a two-sided t-test


?t.test

```{r}

t.test.ozone<- t.test(avg.io ~ ac.type, data=mean.ozone)


```
We can extract information from the t.test.ozone object, such as the p-value

```{r}
t.test.ozone$p.value
t.test.ozone$conf.int[1]
t.test.ozone$conf.int[2]

t.test.ozone[["p.value"]]

```
```{r}
library(ggsignif)

plot.conf.int.2 <- ggplot(data = mean.mean, aes(y=avg.io.type,x=ac.type,fill=ac.type))+
                    geom_col()+ 
                    geom_errorbar(aes(ymin=lower.bound,ymax=upper.bound),width=0.5)+
                    geom_signif(data = mean.ozone, aes(y=avg.io,x=ac.type), comparisons=list(c('Central','Evaporative')),
                                map_signif_level=FALSE,test='t.test',
                                color='black',vjust=1.5,margin_top=0.1)

plot.conf.int.2

```




What's another issue with independence. 
Serial correlation (correlation with time)

Let's look at the data from HW4

What is the mean concentration of the indoor PM2.5 concentrations for each season by different homes

Use the minute-by-minute data

```{r}

SidePak.minute.qa  <- read_csv("..//CE594R_data_science_R//data//SidePak.minute.qa.csv")
```
Calculate the means and 95% confidence intervals

names(SidePak.minute.qa)

```{r}
SidePak.mean.summary <- SidePak.minute.qa %>%
    #ungroup() %>%
    group_by(ac.type, season, Location) %>%
    summarize(Aerosol_mean = mean(Aerosol_ug_m3),
            sd = sd(Aerosol_ug_m3),
            n = sum(!is.na(Aerosol_ug_m3))) %>%
  mutate(tcrit = qt(.975,df=(n-1))) %>% ## two-sided 
  mutate(bound = tcrit*sd/sqrt(n)) %>%
  mutate(lower.95 = Aerosol_mean-bound) %>%
  mutate(upper.95 = Aerosol_mean+bound ) 

```
Plot the geom_bar
```{r}
PM_1 <- ggplot(data=SidePak.mean.summary,
        aes(x=ac.type, y= Aerosol_mean, fill=Location))+
        geom_col()+
        geom_errorbar(aes(ymin=lower.95,ymax=upper.95,width=0.25))+
        theme_bw()+
        facet_grid(Location~season,scales='free_y') +
        labs(y='PM2.5 concentration (ug/m3)') +
        geom_text(y=3,aes(label=paste("n=",n))) +     ## also plot our number of observations?
        coord_cartesian(ylim = c(0,30))
PM_1

```



Are the error bars correct? Is this what we want?

What's the matter?



What do we really want? We want the average of concentration of the average house visit. 

First calculate the mean concentration for each house visit

```{r}
SidePak.visit.sum <- SidePak.minute.qa %>%
                      ungroup() %>%
                      group_by(House.Number,Visit,House.Number.Visit,ac.type,season, Location) %>%
                      summarize(Aerosol_ug_m3= mean(Aerosol_ug_m3,na.rm=T),
                                Date = min(Date),Start_time = min(round.date.time))

```

Evaluate the independence of the home visit means

```{r}
SidePak.visit.sum <- SidePak.visit.sum %>%
  mutate(measurement = ifelse(season == 'Summer' & 
                                House.Number %in% c('H03','H08','H14','H16','H19','H26'),
                              'repeat','single')) %>%
  mutate(house.number.visit = paste(House.Number,Visit,sep=" ")) 

```


Plot the repeats. 
```{r}
ggplot(data = SidePak.visit.sum,  aes(y = house.number.visit, x = Aerosol_ug_m3,fill=measurement))+  
  geom_col(width=0.7)+
  facet_grid(season+ac.type ~Location,scales='free_y' ,space='free') +
  scale_fill_brewer(palette = 'Paired')+
  theme(axis.text = element_text(size = 12)) +
  labs(x = "Aerosol ug/m3", title='',y='')+
  theme_bw()+
  guides(fill=guide_legend(reverse=TRUE)) +
theme(legend.position = 'bottom')+
  theme(axis.text.x = element_text(size=10), axis.text.y = element_text(size=10),
        axis.title = element_text(size = 12),plot.title = element_text(size = 12),
        strip.text = element_text(size=10),
        legend.text = element_text(size = 12))  
```

It appears we have independent observations with the visit means

Now calculate my sample mean and 95% confidence intervals

```{r}
SidePak.mean.summary.correct <- SidePak.visit.sum %>%
    #ungroup() %>%
    group_by(ac.type, season, Location) %>%
    summarize(Aerosol_mean = mean(Aerosol_ug_m3),
            sd = sd(Aerosol_ug_m3),
            n = sum(!is.na(Aerosol_ug_m3))) %>%
  mutate(tcrit = qt(.975,df=(n-1))) %>% ## two-sided 
  mutate(bound = tcrit*sd/sqrt(n)) %>%
  mutate(lower.95 = Aerosol_mean-bound) %>%
  mutate(upper.95 = Aerosol_mean+bound ) 


```

Plot the means and 95% CI


```{r}
PM_2 <- ggplot(data=SidePak.mean.summary.correct,
      aes(x=ac.type, y= Aerosol_mean, fill=Location))+
      geom_col()+
      geom_errorbar(aes(ymin=lower.95,ymax=upper.95,width=0.25))+
      theme_bw()+
      facet_grid(Location~season,scales='free_y') +
      labs(y='PM2.5 concentration (ug/m3)') +
      geom_text(y=3,aes(label=paste("n=",n))) +
      coord_cartesian(ylim = c(0,30))

PM_2
```

```{r}
PM_1 + PM_2 + plot_layout(nrow=1)
```



Questions: 

We calculated the confidence interval of the Indoor/Outdoor Ozone ratio for each air conditiong type using two methods. 
First, we calculated the average and the confidence intervals using the measured I/O for each visit. Then, we calculated the average for each home, and then calculated the average across homes of each air conditioning type

1. Did the average I/O by AC type change between the two different methods?


2. Did the 95% confidence intervals of the average I/O by AC type between the two different methods? How did they change?

  Why?
  
Which approach is most appropriate for evaluating the differences between the two types of homes?


We then calculated average PM2.5 concentrations for each air conditioning type by season and location (indoor/outdoor) 

3. How did the average PM2.5 concentrations change by season and location (indoor/outdoor) when using the minute-by-minute average data to the visit average data? 

4. How did the 95% confidence intervals change from using the minute-by-minute data to using the visit average data?

Which approach is most appropriate and relevant for evaluating the differences between the two types of homes?

Why?








